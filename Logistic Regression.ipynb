{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classification: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 -  Import CSV into pandas\n",
    "\n",
    "1. Create a function to read the CSV file provided into a DataFrame. \n",
    "2. The file imported has NA (not available) values in some columns. These rows need to be dropped as machine learning algorithms cannot process data with missing values. Remember when rows are dropped some (row) indexes will be missing. \n",
    "3. The first step in processing data is to review the data types of the features (columns). \n",
    "4. Use **pandas** features *columns* and *dtypes* to create a dictionary with column names as keys and the datatype as values.\n",
    "5. This function then returns the new dataframe (df) and the df_types dictionary (df_types), where a key-value pair represents column name-column's dtype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(fl):\n",
    "    \n",
    "    # Import the CSV file (fl)\n",
    "    df = pd.read_csv(fl)\n",
    "    \n",
    "    # Drop all rows with NA values\n",
    "    df2 = df.dropna()\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    \n",
    "    # Create a dictionary with keys the column names and values the type of data\n",
    "    df2_types = {}\n",
    "    \n",
    "    for col in df2.columns:\n",
    "        df2_types[col] = df2[col].dtype\n",
    "    \n",
    "    return df2, df2_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2  - Convert categorical (non-numeric) variables \n",
    "\n",
    "Many machine learning algorithms are designed to process numeric data and cannot natively handle categorical data. Therefore as part of the model building process, we must apply pre-processing steps to convert the data into an encoded format which the algorithms can handle.\n",
    "\n",
    "1. In the following function you will identify and convert categorical variables to numeric data type. \n",
    "2. You will need the python *dictionary* \"df2_types\" of the function \"process_data\" we created in task 1. We can use this to identify data in a categorical (non-numeric) data format.\n",
    "3. Create a list \"cat_ls\" of column names which are non-numeric. \n",
    "4. Process each column named in \"cat_ls\" separately. \n",
    "5. For a column name, say \"col_name\", find the *distinct* categories. For example, in column \"gender\" there are 2 categories \"Male\" and \"Female\". \n",
    "6. For a (categorical) column 'C' with *k* categories *k-1* new columns are created and 'C' is replaced by these new columns. For example, the \"*gender*\" column will be replaced by one numerical column. The column \"*smoking_status*\" is to be replaced with 2 numerical columns. This process is referred to as *one-hot encoding*.\n",
    "7. The encoding is done as follows. Suppose there are 3 categories \"cat1\", \"cat2\", \"cat3\" in column 'C'. Create 2 columns with distinct names, say \"cat_level1\", \"cat_level2. If an observation corresponding to a row is 'cat1' then put a 1 in 'cat_level1' and 0 in 'cat_level2' in the same row. If it is 'cat2' put 0 in 'cat_level1' and 1 in 'cat_level2' and put 0 in both if the observation is 'cat3'. \n",
    "8. It is simpler if the column has only 2 categories (like \"gender\"). It will be replaced by 1 column of 1's and 0's. \n",
    "9. The number of columns in the new DataFrame will be generally more than the original. For the *stroke-dataset* this number is 11. Remember to **drop** the old non-numeric columns.  \n",
    "10. Depending on how you do it the column orderings may change. This is important for identifying the output column \"stroke\". \n",
    "11. You may reorder the columns. Suggestion:move \"stroke\" to the last column in the new dataframe. \n",
    "13. You should NOT use any feature-processing modules from **sklearn** or pandas.get_dummies()for this part. If used the maximum mark for this task will not exceed 60%. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numeric():\n",
    "    \n",
    "    # Read the appropriate file, should be in the same directory as the notebook\n",
    "    df, dict_types = process_data(\"Stroke_data_for_part_TWO.csv\")\n",
    "    \n",
    "    # Apply the one hot encoding process outlined to the new dataframe df2\n",
    "    num_ls = [i for i in dict_types if dict_types[i] != \"O\"]\n",
    "    df2 = df[num_ls]\n",
    "    output = df2.iloc[:,-1] \n",
    "    df2 = df2.drop(df.columns[-1], axis=1) \n",
    "    cat_ls = [i for i in dict_types if dict_types[i] == \"O\"]\n",
    "    \n",
    "    for col in cat_ls:\n",
    "        n_values = len(df[col].unique())\n",
    "        n_cols = n_values-1\n",
    "        df_aux = pd.DataFrame(np.zeros(df.shape[0])) \n",
    "        for i in range(n_values-1):\n",
    "            arr = np.zeros(df.shape[0])\n",
    "            for j in range(df.shape[0]):\n",
    "                if df[col][j] == df[col].unique()[i]:\n",
    "                    arr[j] = 1\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            df_aux[i] = arr\n",
    "        df_aux.columns = [col + str(col_name) for col_name in df_aux.columns]\n",
    "        df2 = df2.join(df_aux)\n",
    "    \n",
    "    df2 = df2.join(output)\n",
    "    \n",
    "    return df2        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Generate ndarrays for train and test data\n",
    "\n",
    "1. Convert all columns except \"id\" and \"stroke\" into a numerical feature matrix **X**. The size of the matrix will be *no_of_rows* $\\times$  *(no_of_columns-2)*. The number of columns should be 9. \n",
    "2. Put the values in the \"stroke\" column in the array **y**. \n",
    "3. Use the sklearn [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method to generate *X_train, X_test, y_train. y_test*. \n",
    "5. In the *train_test_split()* method the fraction of data to be split for testing has to be specified. Vary this fraction between .2 to .33. Run your program  a few times to choose  an optimim value. The optimum will correspond to the fraction giving the best accuracy/precision (see Task 5). \n",
    "6. Return the 4 arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_arrays(t_size=0.33):\n",
    "    \n",
    "    # Call the function created in Task 2 to source the encoded data frame\n",
    "    df = convert_to_numeric()\n",
    "    \n",
    "    # Create the X and y objects\n",
    "    # Your code goes here\n",
    "    X = df.iloc[:,1:10]\n",
    "    y = df.iloc[:,-1]\n",
    "    \n",
    "    # Create test/train splits for X and y\n",
    "    # Your code goes here\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=50)\n",
    "    \n",
    "    # Function returns the four newly created objects\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Create the logistic regression model \n",
    "1. In the following function we will use the [liner_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) from sklearn to create and train a logistic regression model. \n",
    "2. The model should be trained on the train set created in task 3. **Do not use the full dataset or test set for training**.\n",
    "2. As this is a binary classification problem (2 classes: \"stroke\", \"no-stroke\") the default model does not need significant adjustment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logitmodel(X, y):\n",
    "    \n",
    "    # Create the logitmodel_stroke model\n",
    "    # Your code goes here\n",
    "    logitmodel_stroke = linear_model.LogisticRegression(max_iter=200)\n",
    "    \n",
    "    # Train the logitmodel_stroke model\n",
    "    # Your code goes here\n",
    "    logitmodel_stroke.fit(X, y)\n",
    "    \n",
    "    return logitmodel_stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - Model evaluation \n",
    "The process for evaluating a classification model is different from a regression model. In regression we have a wide range of values so we measure variance, however classification has a much smaller problem space so we measure how often the correct prediction is made. There are multiple metrics for measuring this, [this article](https://www.mage.ai/blog/definitive-guide-to-accuracy-precision-recall-for-product-developers) and the [Wikipedia page](https://en.wikipedia.org/wiki/Precision_and_recall) provide additional context.\n",
    "\n",
    "1. As this is binary classification there are 2 classes. Class 1 indicates positive stroke risk and class 0 indicates negative stroke risk. \n",
    "2. When testing we use a separate dataset which the model was not trained on. This is essential to observe how the model performs on data it has not seen before.\n",
    "3. In the function below *X_ts* represents the data used to generate test predictions and *y_obs* represents the actual values we are trying to predict. \n",
    "4. We can evaluate a classification model by having it make a set of predictions for a test set (X_ts) and comparing these with the actual values (y_obs).\n",
    "5. Suppose *y_pred* is a predicted value when run on a sample from *X_ts*. We compare it to the corresponding observed value in *y_obs*. There are four potential outcomes from this comparison:\n",
    "\n",
    "    1. *y_pred* = 1 (positive) and *y_obs* = 1 (positive): counted as *true positive*.\n",
    "    2. *y_pred* = 1 (positive) and *y_obs* = 0 (negative): counted as *false positive*. \n",
    "    3. *y_pred* = 0 (negative) and *y_obs* = 0 (negative): counted as *true negative*. \n",
    "    4. *y_pred* = 0 (positive) and *y_obs* = 1 (negative): counted as *false negative*. \n",
    "    \n",
    "5. Count all the 4 cases for the entire sample input to the function *evaluate_logitmodel* and store them in 4 variables: *tp*, *fp*, *tn* and *fn*. For example, *tp* will give total number of true positives and *tn* the total of true negatives. \n",
    "6. The two metrics we will be using for evaluation are *accuracy* and *precision*. The formula for these is below. \n",
    "$$acc = \\frac{tp+tn}{tp+tn+fp+fn} \\quad\\text{(accuracy)}, \\quad prec = \\frac{tp}{tp + fp} \\quad\\text{(precision)}$$\n",
    "\n",
    "7. Run the model training/evaluation process for 5 different test/train split ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model object is the output of the function fit_logitmodelto obtain y_pred\n",
    "def evaluate_logitmodel(model, X_ts,  y_obs):\n",
    "    \n",
    "    # Use the .predict() method of the model to generate a set of predictions for X_ts\n",
    "    # Your code goes here\n",
    "    y_preds = model.predict(X_ts)\n",
    "    \n",
    "    # Determine the tp, fp, tn and fn values for the prediction set\n",
    "    # Your code goes here\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(y_preds.shape[0]):\n",
    "        if y_preds[i] == 1 and y_obs.iloc[i,] == 1:\n",
    "            tp += 1\n",
    "        elif  y_preds[i] == 1 and y_obs.iloc[i,] == 0:   \n",
    "            fp += 1\n",
    "        elif  y_preds[i] == 0 and y_obs.iloc[i,] == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    \n",
    "    # Calculate the accuracy and precision values\n",
    "    # Your code goes here\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    prec = tp/(tp+fp)\n",
    "    \n",
    "    return acc, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size 0.20 -> Accuracy = 0.9503650, Precision = 1.00, Accuracy/Precision = 0.9503650\n",
      "Test size 0.24 -> Accuracy = 0.9476886, Precision = 1.00, Accuracy/Precision = 0.9476886\n",
      "Test size 0.27 -> Accuracy = 0.9481081, Precision = 1.00, Accuracy/Precision = 0.9481081\n",
      "Test size 0.30 -> Accuracy = 0.9503891, Precision = 1.00, Accuracy/Precision = 0.9503891\n",
      "Test size 0.33 -> Accuracy = 0.9513705, Precision = 1.00, Accuracy/Precision = 0.9513705\n"
     ]
    }
   ],
   "source": [
    "t_sizes = [0.2, 0.24, 0.27, 0.30, 0.33]\n",
    "for size in t_sizes:\n",
    "    X_train, X_test, y_train, y_test = create_arrays(size)\n",
    "    logitmodel_stroke = fit_logitmodel(X_train, y_train)\n",
    "    acc, prec = evaluate_logitmodel(logitmodel_stroke, X_test,  y_test)\n",
    "    print(\"Test size %.2f -> Accuracy = %.7f, Precision = %.2f, Accuracy/Precision = %.7f\" % (size, acc, prec,(acc/prec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluating the model with different sizes for the train and test data sets, the following results were obtained. The precision of the model was iqual to 1 for all the sizes of the train and test data sets. However, the accuracy of the model changed as the size of the test set increased. At first, with a test set size of 20% of the data, the acurracy was 95.04%. When the test set size increased to 24% and 27% of the data, the accuracy decreassed to 94.77% and 94.81%. When the test set size increased to 30% of the data, the accuracy increaded again to 95.04% and when the test set size increased to %33 of the data, the highest accuracy of 95.14% was obtained. \n",
    "\n",
    "There was a difference in accuracy and precision with every size for the test set. The accuracy meassures the amount of true predictions over all the predictions. The precition meassure the amount of true possitive over all the possitive predictions. This means that the model only missed by classifing possitive observations as negative, but all the possitive predictions were correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a fixed train/test data evaluate the metrics on the train data (*X_train*) and test (*X_test*) seprately and record the valuse of the metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9516263552960801\n",
      "Precision =  1.0\n"
     ]
    }
   ],
   "source": [
    "# Train size is equal to 35% of all the data\n",
    "X_train, X_test, y_train, y_test = create_arrays(0.35)\n",
    "logitmodel_stroke = fit_logitmodel(X_train, y_train)\n",
    "acc, prec = evaluate_logitmodel(logitmodel_stroke, X_test,  y_test)\n",
    "print(\"Accuracy = \", acc)\n",
    "print(\"Precision = \", prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
