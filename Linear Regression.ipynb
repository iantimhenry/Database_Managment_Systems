{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 1: Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries. No other libraries are required for this task.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 1 -  Import CSV into pandas\n",
    "\n",
    "1. Create a function to read the csv file provided into a DataFrame. \n",
    "3. First step in processing data is to list the data types of the columns. \n",
    "4. Use **pandas** features *columns* and *dtypes* to create a dictionary with column names as keys and the datatype as values.\n",
    "5. This function then returns the new dataframe (df) and the df_types dictionary (df_types), where a key-value pair represents column name-column's dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(fl):\n",
    "    \n",
    "    # Import the CSV file (fl)\n",
    "    df = pd.read_csv(fl)\n",
    "    \n",
    "    # Create a dictionary with keys the column names and values the type of data\n",
    "    df_types = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df_types[col] = df[col].dtype\n",
    "        \n",
    "    return df, df_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 2 - Splitting data\n",
    "\n",
    "1. Split the data into 2 dataframes: called *df_train* and *df_test*. \n",
    "2. Use **pandas** DataFrame.sample to pick around 75% randomly as the training dataframe. \n",
    "3. Put the rest in test dataframe. Use DataFrame.drop() function on the full dataframe to drop the entries in *df_train*.\n",
    "4. Do NOT use methods from **sklearn**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    df_train = None\n",
    "    df_test = None\n",
    "    \n",
    "    # Assign 75% of input data(df) to df_train and the rest to df_test\n",
    "    \n",
    "    df_train = df.sample(frac=0.75)\n",
    "    df_test = df.drop(df_train.index)\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 3 - Scaling data\n",
    "\n",
    "1. In the dataframe each column is a feature. In the real estate data there are 8 features. The first column (number 0) is just an index number - ignore it. We will only consider 7 features (1-7). \n",
    "2. These are all of different orders of magnitude. For example, the \"transaction date\" is in thousands (very high value) but the \"number of ...stores\" is in one or two digits (low). So we scale them to be more consistent, otherwise transaction date could dominate the predicted outcome of the regression model.\n",
    "3. Find the *maximum* ($M$), *minimum* ($m$) and *mean* ($av$) of each column. Each entry $x_i$ is scaled as:\n",
    "\n",
    "$$ x_i \\rightarrow \\frac{x_i -av}{M-m}$$\n",
    "\n",
    "4. We will apply scaling to the *numpy* arrays. \n",
    "5. In the function below the input feature matrix is $X\\_in$. \n",
    "6. You may create a helper function. Check the numpy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scale_features(df):\n",
    "    \n",
    "    #the feature vectors as a matrix\n",
    "    X_in = np.array(df.iloc[:,1:7])\n",
    "    \n",
    "    #the output vector\n",
    "    y = np.array(df.iloc[:, 7])\n",
    "    \n",
    "    #a matrix of same shape as X_in with all zeros\n",
    "    X_scaled = np.zeros(X_in.shape)\n",
    "    pass\n",
    "\n",
    "    #apply scaling to each column of X_in separately and store them in X_scaled \n",
    "    for i in range(X_in.shape[1]):\n",
    "        X_scaled[:,i] = (X_in[:,i] - X_in[:,i].mean())/(X_in[:,i].max() - X_in[:,i].min())\n",
    "    \n",
    "    return X_scaled, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 4 - Model training\n",
    "\n",
    "We are now ready to build the linear regression model. \n",
    "1. We use the **sklearn** [linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) class to build the model. \n",
    "2. Answer the questions that follow. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#4 marks\n",
    "def fit_linearModel(X, y):\n",
    "\n",
    "    # return the LinearRegression() estimator that has been fitted, so that\n",
    "    # it can be used for the next question\n",
    "    \n",
    "    # Your code goes here\n",
    "    linmodel_realest = linear_model.LinearRegression().fit(X, y)\n",
    "    \n",
    "    return linmodel_realest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.60262607 -11.47694919 -29.32875796  10.40237297  20.61405328\n",
      "  -1.68558322]\n",
      "37.486774193548015\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "df, df_types = process_data(\"Real_estate_data_for part_ONE.csv\")\n",
    "\n",
    "# Train test split\n",
    "df_train, df_test = train_test_split(df)\n",
    "\n",
    "# Scale the training data\n",
    "X_scaled, y = scale_features(df_train)\n",
    "\n",
    "# Train model\n",
    "linmodel_realest = fit_linearModel(X_scaled, y)\n",
    "\n",
    "# Get coeficients\n",
    "print(linmodel_realest.coef_)\n",
    "\n",
    "# Get intercept\n",
    "print(linmodel_realest.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.32358509 -12.97158811 -28.15098444  10.23168245  18.92680948\n",
      "  -2.15219871]\n",
      "38.344516129031135\n",
      "[  4.71406968 -12.02453915 -26.4566264   13.22445595  20.82562611\n",
      "  -1.83452947]\n",
      "37.15741935484101\n",
      "[  4.68987847 -12.01646868 -34.78219122  11.06351945  14.06002904\n",
      "  -4.6879378 ]\n",
      "38.219999999999615\n",
      "[  5.07662423 -12.62305316 -26.7688618   13.57717154  16.1448583\n",
      "  -0.16292757]\n",
      "37.2109677419355\n",
      "[  4.94855113 -10.01230455 -26.31828498  13.03571379  18.87453794\n",
      "   1.16075681]\n",
      "38.03677419354847\n"
     ]
    }
   ],
   "source": [
    "# Run the model 5 times with different training sets\n",
    "for i in range(5):\n",
    "    \n",
    "    # Train test split (every repetition gets different datasets)\n",
    "    df_train, df_test = train_test_split(df)\n",
    "    \n",
    "    # Get the training data scaled\n",
    "    X_scaled, y = scale_features(df_train)\n",
    "    \n",
    "    # Train the model \n",
    "    linmodel_realest = fit_linearModel(X_scaled, y)\n",
    "    \n",
    "    # Get coefficients\n",
    "    print(linmodel_realest.coef_)\n",
    "    \n",
    "    # Get intercept\n",
    "    print(linmodel_realest.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 5 - Model evaluation\n",
    "\n",
    "Now we use the test data to check the accuracy of the model. We will use root-mean-square error (RMSE) to test accuracy.\n",
    "\n",
    "1. RMSE is the square-root of the average of the squared errors between the predicted and observed value. \n",
    "2. In the following function you will find the RMSE for the fitted model. \n",
    "3. You should use the returned LinearRegression() object that is return by the function *fit_linearModel* above.\n",
    "4. You should write the RMSE function yourself. Do NOT use **sklearn** *score*() method. However you may use the *predict*() method. \n",
    "5. Test for accuracy on 5 different train-test sets and report the average RMSE value. Write a few comments on how to improve accuracy of prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#X and y correspond to the test data and model is the output of fit_linearModel()\n",
    "def check_rmse(model, X, y):\n",
    "    rmse = 0\n",
    "\n",
    "    # Update the variable rmse\n",
    "    y_preds = model.predict(X)\n",
    "    rmse = np.sqrt(sum((y_preds-y)**2)/(y.shape[0]))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [9.053993457009698, 8.001288823097477, 8.736516725876907, 8.191975860902698, 8.957096288378471]\n",
      "Mean score:  8.58817423105305\n"
     ]
    }
   ],
   "source": [
    "# Import the data \n",
    "df, df_types = process_data(\"Real_estate.csv\")\n",
    "\n",
    "# Initialize list with scores\n",
    "scores = []\n",
    "\n",
    "# Run the model 5 times with different train and test datasets\n",
    "for i in range(5):\n",
    "    \n",
    "    # Train test split (every repetition gets different datasets)\n",
    "    df_train, df_test = train_test_split(df)\n",
    "    \n",
    "    # Scale train data\n",
    "    X_train_scaled, y_train = scale_features(df_train)\n",
    "    \n",
    "    # Scale test data\n",
    "    X_test_scaled, y_test = scale_features(df_train)\n",
    "    \n",
    "    # Fit model\n",
    "    linmodel_realest = fit_linearModel(X_scaled, y)\n",
    "    \n",
    "    # Evaluate model\n",
    "    rmse = check_rmse(linmodel_realest, X_test_scaled, y_test)\n",
    "    \n",
    "    # Save all evaluations \n",
    "    scores.append(rmse)\n",
    "\n",
    "# Print the list of scores\n",
    "print(\"Scores: \", scores)\n",
    "\n",
    "# Print average of scores\n",
    "print(\"Mean score: \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on how to improve accuracy\n",
    "\n",
    "- Try to use different sizes for the train and test data sets.\n",
    "- Review the independence and correlation within the variables.\n",
    "- Select only relevant variables for the regression. These are the variables more correlated with the target variable, the variables with less correlation with the target variable can be ignored.\n",
    "- Try different methods for scale and normalize the data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
